{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e06f28ed",
   "metadata": {},
   "source": [
    "- **Based on the findings and insights from the data exploration, we will now proceed with data preprocessing.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48c20a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03c6b827",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>AGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>...</th>\n",
       "      <th>BILL_AMT4</th>\n",
       "      <th>BILL_AMT5</th>\n",
       "      <th>BILL_AMT6</th>\n",
       "      <th>PAY_AMT1</th>\n",
       "      <th>PAY_AMT2</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default.payment.next.month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>26</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3272.0</td>\n",
       "      <td>3455.0</td>\n",
       "      <td>3261.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>14331.0</td>\n",
       "      <td>14948.0</td>\n",
       "      <td>15549.0</td>\n",
       "      <td>1518.0</td>\n",
       "      <td>1500.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>28314.0</td>\n",
       "      <td>28959.0</td>\n",
       "      <td>29547.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>57</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>20940.0</td>\n",
       "      <td>19146.0</td>\n",
       "      <td>19131.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>36681.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID  LIMIT_BAL  SEX  EDUCATION  MARRIAGE  AGE  PAY_0  PAY_2  PAY_3  PAY_4  \\\n",
       "0   1    20000.0    2          2         1   24      2      2     -1     -1   \n",
       "1   2   120000.0    2          2         2   26     -1      2      0      0   \n",
       "2   3    90000.0    2          2         2   34      0      0      0      0   \n",
       "3   4    50000.0    2          2         1   37      0      0      0      0   \n",
       "4   5    50000.0    1          2         1   57     -1      0     -1      0   \n",
       "\n",
       "   ...  BILL_AMT4  BILL_AMT5  BILL_AMT6  PAY_AMT1  PAY_AMT2  PAY_AMT3  \\\n",
       "0  ...        0.0        0.0        0.0       0.0     689.0       0.0   \n",
       "1  ...     3272.0     3455.0     3261.0       0.0    1000.0    1000.0   \n",
       "2  ...    14331.0    14948.0    15549.0    1518.0    1500.0    1000.0   \n",
       "3  ...    28314.0    28959.0    29547.0    2000.0    2019.0    1200.0   \n",
       "4  ...    20940.0    19146.0    19131.0    2000.0   36681.0   10000.0   \n",
       "\n",
       "   PAY_AMT4  PAY_AMT5  PAY_AMT6  default.payment.next.month  \n",
       "0       0.0       0.0       0.0                           1  \n",
       "1    1000.0       0.0    2000.0                           1  \n",
       "2    1000.0    1000.0    5000.0                           0  \n",
       "3    1100.0    1069.0    1000.0                           0  \n",
       "4    9000.0     689.0     679.0                           0  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defining the path to the datasets folder\n",
    "data_dir = \"datasets\"\n",
    "dataset_path = os.path.join(data_dir, \"UCI_Credit_Card.csv\")\n",
    "\n",
    "# Loading the CSV file into a DataFrame\n",
    "dataframe = pd.read_csv(dataset_path)\n",
    "\n",
    "# Displaying the first few rows to confirm loading\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2621814",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Renaming the target column\n",
    "dataframe.rename(columns={'default.payment.next.month': 'default_payment_next_month'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fceefd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID                             0\n",
       "LIMIT_BAL                      0\n",
       "SEX                            0\n",
       "EDUCATION                      0\n",
       "MARRIAGE                      54\n",
       "AGE                            0\n",
       "PAY_0                          0\n",
       "PAY_2                          0\n",
       "PAY_3                          0\n",
       "PAY_4                          0\n",
       "PAY_5                          0\n",
       "PAY_6                          0\n",
       "BILL_AMT1                      0\n",
       "BILL_AMT2                      0\n",
       "BILL_AMT3                      0\n",
       "BILL_AMT4                      0\n",
       "BILL_AMT5                      0\n",
       "BILL_AMT6                      0\n",
       "PAY_AMT1                       0\n",
       "PAY_AMT2                       0\n",
       "PAY_AMT3                       0\n",
       "PAY_AMT4                       0\n",
       "PAY_AMT5                       0\n",
       "PAY_AMT6                       0\n",
       "default_payment_next_month     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Replacing 0 with NaN in the MARRIAGE column\n",
    "dataframe = dataframe.replace({'MARRIAGE': {0: np.nan}})\n",
    "\n",
    "# Replacing 4, 5, and 6 with 0 in the EDUCATION column to consider them as 'others'\n",
    "dataframe = dataframe.replace({'EDUCATION': {4: 0, 5: 0, 6: 0}})\n",
    "\n",
    "# Displaying missing values in each column\n",
    "dataframe.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7246f11a",
   "metadata": {},
   "source": [
    "- Now only `MARRIAGE` column have missing values, which we will handle in the preprocessing step after splitting the data into training and testing sets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611ac548",
   "metadata": {},
   "source": [
    "**Handling Outliers**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f57db1cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(14604, 25)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_columns = ['LIMIT_BAL',\n",
    "        'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "        'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6',]\n",
    "\n",
    "# Function to detect Outliers in Numerical Variables using IQR Method\n",
    "def detect_outliers(df, column):\n",
    "    Q1 = df[column].quantile(0.25)\n",
    "    Q3 = df[column].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers = df[(df[column] < lower_bound) | (df[column] > upper_bound)][column]\n",
    "    return len(outliers), lower_bound, upper_bound\n",
    "\n",
    "# Creating a copy if df to avoid modifying the original DataFrame\n",
    "df1 = dataframe.copy()\n",
    "\n",
    "for col in numerical_columns:\n",
    "    outlier_count, lower, upper = detect_outliers(df1, col)\n",
    "    df1 = df1[(df1[col] >= lower) & (df1[col] <= upper)]\n",
    "df1.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Printing the shape of df1 after removing outliers\n",
    "df1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371d1ae3",
   "metadata": {},
   "source": [
    "- If we remove outliers, we will lose around 50% of the data, so we will not remove outliers. Instead, we can apply log transformation for skewed numerical variables or use tree-based models which are robust to skewed distributions and outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad018fd",
   "metadata": {},
   "source": [
    "**Feature Engineering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8fdc23bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LIMIT_BAL</th>\n",
       "      <th>SEX</th>\n",
       "      <th>EDUCATION</th>\n",
       "      <th>MARRIAGE</th>\n",
       "      <th>PAY_0</th>\n",
       "      <th>PAY_2</th>\n",
       "      <th>PAY_3</th>\n",
       "      <th>PAY_4</th>\n",
       "      <th>PAY_5</th>\n",
       "      <th>PAY_6</th>\n",
       "      <th>...</th>\n",
       "      <th>PAY_AMT3</th>\n",
       "      <th>PAY_AMT4</th>\n",
       "      <th>PAY_AMT5</th>\n",
       "      <th>PAY_AMT6</th>\n",
       "      <th>default_payment_next_month</th>\n",
       "      <th>Age_Groups</th>\n",
       "      <th>Avg_Bill_Amt</th>\n",
       "      <th>Avg_Pay_Amt</th>\n",
       "      <th>Avg_Delay_Score</th>\n",
       "      <th>Average_Credit_Utilization_Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-2</td>\n",
       "      <td>-2</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>20-25</td>\n",
       "      <td>1284.00</td>\n",
       "      <td>114.83</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>120000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>25-30</td>\n",
       "      <td>2846.17</td>\n",
       "      <td>833.33</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>90000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>5000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>30-35</td>\n",
       "      <td>16942.17</td>\n",
       "      <td>1836.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1200.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1069.0</td>\n",
       "      <td>1000.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35-40</td>\n",
       "      <td>38555.67</td>\n",
       "      <td>1398.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50000.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>689.0</td>\n",
       "      <td>679.0</td>\n",
       "      <td>0</td>\n",
       "      <td>55-60</td>\n",
       "      <td>18223.17</td>\n",
       "      <td>9841.50</td>\n",
       "      <td>-0.33</td>\n",
       "      <td>0.36</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LIMIT_BAL  SEX  EDUCATION  MARRIAGE  PAY_0  PAY_2  PAY_3  PAY_4  PAY_5  \\\n",
       "0    20000.0    2          2       1.0      2      2     -1     -1     -2   \n",
       "1   120000.0    2          2       2.0     -1      2      0      0      0   \n",
       "2    90000.0    2          2       2.0      0      0      0      0      0   \n",
       "3    50000.0    2          2       1.0      0      0      0      0      0   \n",
       "4    50000.0    1          2       1.0     -1      0     -1      0      0   \n",
       "\n",
       "   PAY_6  ...  PAY_AMT3  PAY_AMT4  PAY_AMT5  PAY_AMT6  \\\n",
       "0     -2  ...       0.0       0.0       0.0       0.0   \n",
       "1      2  ...    1000.0    1000.0       0.0    2000.0   \n",
       "2      0  ...    1000.0    1000.0    1000.0    5000.0   \n",
       "3      0  ...    1200.0    1100.0    1069.0    1000.0   \n",
       "4      0  ...   10000.0    9000.0     689.0     679.0   \n",
       "\n",
       "   default_payment_next_month  Age_Groups  Avg_Bill_Amt  Avg_Pay_Amt  \\\n",
       "0                           1       20-25       1284.00       114.83   \n",
       "1                           1       25-30       2846.17       833.33   \n",
       "2                           0       30-35      16942.17      1836.33   \n",
       "3                           0       35-40      38555.67      1398.00   \n",
       "4                           0       55-60      18223.17      9841.50   \n",
       "\n",
       "   Avg_Delay_Score  Average_Credit_Utilization_Ratio  \n",
       "0            -0.33                              0.06  \n",
       "1             0.50                              0.02  \n",
       "2             0.00                              0.19  \n",
       "3             0.00                              0.77  \n",
       "4            -0.33                              0.36  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def initiate_feature_engineering(dataframe: pd.DataFrame) -> pd.DataFrame:\n",
    "\n",
    "    # Age Groups\n",
    "    dataframe['Age_Groups'] = pd.cut(dataframe['AGE'], bins=[20, 25, 30, 35, 40, 45, 50, 55, 60, np.inf], \n",
    "                                 labels=['20-25', '25-30', '30-35', '35-40', '40-45', '45-50', '50-55', '55-60', '60+'], \n",
    "                                 right=False)\n",
    "    dataframe = dataframe.drop(columns=['AGE'])\n",
    "\n",
    "    # Average Bill Amount\n",
    "    dataframe['Avg_Bill_Amt'] = dataframe[['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']].mean(axis=1).round(2)\n",
    "\n",
    "    # Average Payment Amount\n",
    "    dataframe['Avg_Pay_Amt'] = dataframe[['PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6']].mean(axis=1).round(2)\n",
    "\n",
    "    # Average Delay Score Calculation\n",
    "    dataframe['Avg_Delay_Score'] = dataframe[['PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']].mean(axis=1).round(2)\n",
    "    \n",
    "    # Average Credit Utilization Ratio Calculation\n",
    "    bill_amt_cols = ['BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6']\n",
    "    utilization_ratios = []\n",
    "    for col in bill_amt_cols:\n",
    "        dataframe[f'UTIL_{col}'] = dataframe[col] / dataframe['LIMIT_BAL']\n",
    "        utilization_ratios.append(f'UTIL_{col}')\n",
    "    dataframe['Average_Credit_Utilization_Ratio'] = dataframe[utilization_ratios].mean(axis=1).round(2)\n",
    "    dataframe = dataframe.drop(columns=[col for col in dataframe.columns if 'UTIL_' in str(col)])\n",
    "\n",
    "    # droping 'ID' column if exists\n",
    "    if 'ID' in dataframe.columns:\n",
    "        dataframe = dataframe.drop(columns=['ID'])\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "dataframe = initiate_feature_engineering(dataframe)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47599829",
   "metadata": {},
   "source": [
    "- We created 5 new features based on the existing features:\n",
    "  - `Age_Groups`: Categorizing age into groups.\n",
    "  - `Avg_Bill_Amt`: Average of the bill amounts for the last 6 months.\n",
    "  - `Avg_Pay_Amt`: Average of the payment amounts for the last 6 months.\n",
    "  - `Avg_Delay_Score`: Average delay score for the last 6 months.\n",
    "  - `Avg_Utilization_Ratio`: Average utilization ratio for the last 6 months. (Payment amount divided by bill amount for each month then averaged)\n",
    "\n",
    "- We also dropped 2 columns:\n",
    "  - `AGE`: As we created age groups, the original `AGE` column is no longer needed.\n",
    "  - `ID`: Unique identifier for each customer, which does not contribute to the prediction of default payment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea3b485f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(29875, 28)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop duplicates if any\n",
    "if dataframe.duplicated().any():\n",
    "    dataframe = dataframe.drop_duplicates()\n",
    "\n",
    "# Checking the shape of the DataFrame after adding new features\n",
    "dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b58d49b",
   "metadata": {},
   "source": [
    "- Now we have 29875 rows and 28 columns in the dataset after performing feature engineering and removing duplicate rows."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b31d29",
   "metadata": {},
   "source": [
    "**Data Splitting**\n",
    "- We will split the dataset into training and testing sets using an 75-25 split. This will allow us to train the model on a larger portion of the data and evaluate its performance on unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d21bc2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features (X): (29875, 27)\n",
      "Shape of target (y): (29875,)\n"
     ]
    }
   ],
   "source": [
    "# Split data into X (features) and y (target)\n",
    "TARGET_COLUMN = 'default_payment_next_month'\n",
    "\n",
    "X = dataframe.drop(columns= TARGET_COLUMN)\n",
    "y = dataframe[TARGET_COLUMN]\n",
    "\n",
    "# Displaying the shape of the features and target\n",
    "print(f\"Shape of features (X): {X.shape}\")\n",
    "print(f\"Shape of target (y): {y.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7fa8bfe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features (X_train): (22406, 27)\n",
      "Shape of testing features (X_test): (7469, 27)\n"
     ]
    }
   ],
   "source": [
    "# Spliting the dataset into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Splitting the dataset into training and testing sets with a 75-25 split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1, stratify=y)\n",
    "\n",
    "# Displaying the shapes of the training and testing sets\n",
    "print(f\"Shape of training features (X_train): {X_train.shape}\")\n",
    "print(f\"Shape of testing features (X_test): {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7e43c12c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default_payment_next_month\n",
       "0    0.78\n",
       "1    0.22\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking proportions of default payment next month in training data\n",
    "y_train.value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76512d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default_payment_next_month\n",
       "0    0.78\n",
       "1    0.22\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking proportions of default payment next month in testing data\n",
    "y_test.value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "329d04a2",
   "metadata": {},
   "source": [
    "- We have same proportion of target variable in both training and testing sets, which is good for model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21e5dbdc",
   "metadata": {},
   "source": [
    "**Data preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "006219c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of scaled training features (X_train_scaled): (22406, 28)\n",
      "Shape of scaled testing features (X_test_scaled): (7469, 28)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "def get_data_transformer_object():\n",
    "    numerical_columns = [\n",
    "        'LIMIT_BAL',\n",
    "        'BILL_AMT1', 'BILL_AMT2', 'BILL_AMT3', 'BILL_AMT4', 'BILL_AMT5', 'BILL_AMT6',\n",
    "        'PAY_AMT1', 'PAY_AMT2', 'PAY_AMT3', 'PAY_AMT4', 'PAY_AMT5', 'PAY_AMT6', \n",
    "        'Avg_Bill_Amt', 'Avg_Pay_Amt', 'Avg_Delay_Score', 'Average_Credit_Utilization_Ratio'\n",
    "    ]\n",
    "\n",
    "    nominal_columns = ['SEX', 'MARRIAGE']\n",
    "\n",
    "    ordinal_columns = ['EDUCATION', 'Age_Groups', 'PAY_0', 'PAY_2', 'PAY_3', 'PAY_4', 'PAY_5', 'PAY_6']\n",
    "\n",
    "    numerical_pipeline = Pipeline(steps=[('imputation', SimpleImputer(strategy='median')),\n",
    "                                        ('scaling', StandardScaler())])\n",
    "\n",
    "    nominal_pipeline = Pipeline(steps=[('imputation', SimpleImputer(strategy='most_frequent')),\n",
    "                                        ('encoding', OneHotEncoder(handle_unknown ='ignore', drop='first'))])\n",
    "                \n",
    "    ordinal_pipeline = Pipeline(steps=[('imputation', SimpleImputer(strategy='most_frequent')),\n",
    "                                            ('encoding', OrdinalEncoder(handle_unknown='use_encoded_value', unknown_value=-1))])\n",
    "\n",
    "    preprocessor = ColumnTransformer([(\"numerical_pipeline\", numerical_pipeline, numerical_columns),\n",
    "                                            (\"nominal_pipeline\", nominal_pipeline, nominal_columns),\n",
    "                                            (\"ordinal_pipeline\", ordinal_pipeline, ordinal_columns)])\n",
    "            \n",
    "    return preprocessor\n",
    "\n",
    "# Creating the preprocessor object\n",
    "preprocessor = get_data_transformer_object()\n",
    "\n",
    "# performing fit and transform on the training data, and transform on the test data\n",
    "X_train_scaled = preprocessor.fit_transform(X_train)\n",
    "X_test_scaled = preprocessor.transform(X_test)\n",
    "\n",
    "# Displaying the shape of the scaled training and testing data\n",
    "print(f\"Shape of scaled training features (X_train_scaled): {X_train_scaled.shape}\")\n",
    "print(f\"Shape of scaled testing features (X_test_scaled): {X_test_scaled.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7049cd82",
   "metadata": {},
   "source": [
    "- In this data preprocessing step, we use `ColumnTransformer` and `Pipeline` from `sklearn` to apply different preprocessing steps to different types of features:\n",
    "    - For numerical features, we handled missing values by replacing them with the median of the column, and then scaled the numerical features using `StandardScaler`.\n",
    "    - For nominal categorical features, we handled missing values by replacing them with the most frequent value (mode) in the column, and then applied `OneHotEncoder` to convert them into numerical format. In this case, we used `drop='first'` to avoid the dummy variable trap.\n",
    "    - For ordinal categorical features, we handled missing values by replacing them with the most frequent value (mode) in the column, and then applied `OrdinalEncoder` to convert them into numerical format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "265cc80c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in X_train_scaled: 0\n",
      "Missing values in X_test_scaled: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values in the scaled training and testing data\n",
    "print(f\"Missing values in X_train_scaled: {np.isnan(X_train_scaled).sum()}\")\n",
    "print(f\"Missing values in X_test_scaled: {np.isnan(X_test_scaled).sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91a74efb",
   "metadata": {},
   "source": [
    "**Handling class imbalance in training data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bd4a896d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "default_payment_next_month\n",
       "0    0.56\n",
       "1    0.44\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Applying SMOTE for balancing the training dataset\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(sampling_strategy=0.8, random_state=1)\n",
    "X_train_balanced, y_train_balanced = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "# Displaying the class distribution in the balanced training data\n",
    "y_train_balanced.value_counts(normalize=True).round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2989247",
   "metadata": {},
   "source": [
    "- We used `SMOTE` (Synthetic Minority Over-sampling Technique) to handle class imbalance in the training data. This technique generates synthetic samples for the minority class to balance the class distribution.\n",
    "- We set the `sampling_strategy` to 0.8, which means we want the minority class to be 80% of the majority class after resampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5683a1d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training array (train_arr): (31411, 29)\n",
      "Shape of testing array (test_arr): (7469, 29)\n"
     ]
    }
   ],
   "source": [
    "# Combining the balanced training features and target into a single array\n",
    "train_arr = np.c_[X_train_balanced, np.array(y_train_balanced)]\n",
    "\n",
    "# Combining the testing features and target into a single array\n",
    "test_arr = np.c_[X_test_scaled, np.array(y_test)]\n",
    "\n",
    "# Displaying the shapes of the training and testing arrays\n",
    "print(f\"Shape of training array (train_arr): {train_arr.shape}\")\n",
    "print(f\"Shape of testing array (test_arr): {test_arr.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c602d18e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in train_arr: 0\n",
      "Missing values in test_arr: 0\n"
     ]
    }
   ],
   "source": [
    "# Checking for missing values in the training and testing arrays\n",
    "print(f\"Missing values in train_arr: {np.isnan(train_arr).sum()}\")\n",
    "print(f\"Missing values in test_arr: {np.isnan(test_arr).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "61b7c1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the training array has unique rows\n",
    "np.unique(train_arr, axis=0).shape[0] == train_arr.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3b864873",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if the testing array has unique rows\n",
    "np.unique(test_arr, axis=0).shape[0] == test_arr.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dceaef4",
   "metadata": {},
   "source": [
    "**Saving Train and Test Arrays**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff3aa868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.29578711, -0.70041989, -0.69576597, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.91049328, -0.01483345,  0.01067294, ...,  2.        ,\n",
       "         2.        ,  1.        ],\n",
       "       [-0.37262538, -0.67263935, -0.67164271, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.64870089, -0.29601293, -0.27943156, ...,  2.        ,\n",
       "         2.        ,  1.        ],\n",
       "       [-0.37499262,  0.67907446,  0.72725303, ...,  2.        ,\n",
       "         2.        ,  1.        ],\n",
       "       [-0.95458115, -0.30502792, -0.28322979, ...,  3.        ,\n",
       "         3.        ,  1.        ]], shape=(31411, 29))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6b898c38",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.29578711, -0.70041989, -0.69576597, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.91049328, -0.01483345,  0.01067294, ...,  2.        ,\n",
       "         2.        ,  1.        ],\n",
       "       [-0.37262538, -0.67263935, -0.67164271, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [-0.64870089, -0.29601293, -0.27943156, ...,  2.        ,\n",
       "         2.        ,  1.        ],\n",
       "       [-0.37499262,  0.67907446,  0.72725303, ...,  2.        ,\n",
       "         2.        ,  1.        ],\n",
       "       [-0.95458115, -0.30502792, -0.28322979, ...,  3.        ,\n",
       "         3.        ,  1.        ]], shape=(31411, 29))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fd22e239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating new directory to save csv output files\n",
    "csv_output_dir = \"csv_outputs\"\n",
    "os.makedirs(csv_output_dir, exist_ok=True)\n",
    "\n",
    "# Saving the train data as a numPy array\n",
    "train_data_path = os.path.join(csv_output_dir, \"train_data.npy\")\n",
    "np.save(train_data_path, train_arr)\n",
    "\n",
    "# Saving the test data as a numPy array\n",
    "test_data_path = os.path.join(csv_output_dir, \"test_data.npy\")\n",
    "np.save(test_data_path, test_arr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c5e0358",
   "metadata": {},
   "source": [
    "- Saved the preprocessed training and testing arrays to `.npy` files for training and testing machine learning models. This allows us to quickly load the data without having to repeat the preprocessing steps."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
